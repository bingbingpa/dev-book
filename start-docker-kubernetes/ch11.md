# 11장 애플리케이션 배포를 위한 고급 설정

# 11.1 포드의 자원 사용량 제한

- 쿠버네티스와 같은 컨테이너 오케스트레이션 툴의 가장 큰 장점 중 하나는 여러 대의 서버를 묶어 리소스 풀로 사용할 수 있다는 것이다.
  - 클러스터의 CPU 나 메모리 등의 자원이 부족할 때, 필요한 용량만큼의 서버를 동적으로 추가함으로써 수평적으로 확장할 수 있기 때문이다.
- 자원 활용률(Utilization)은 서버 클러스터에서 자원을 얼마나 효율적으로, 빠짐없이 사용하고 있는지를 의미한다.

## 11.1.1 컨테이너와 포드의 자원 사용량 제한 : Limits

- 자원 할당량을 설정하지 않으면 포드의 컨테이너가 노드의 물리 자원을 모두 사용할 수 있기 때문에 노드의 자원이 모두 고갈되는 상황이 발생할 수도 있다.

## 11.1.2 컨테이너와 포드의 자원 사용량 제한하기: Requests

- `Requests` 는 **‘적어도 이 만큼의 자원은 컨테이너에게 보장돼야 한다’**는 것을  의미한다.
- 오버커밋(Overcommit)은 한정된 컴퓨팅 자원을 효율적으로 사용하기 위한 방법으로, 사용할 수 있는 자원보다 더 많은 양을 가상 머신이나 컨테이너에게 할당함으로써 전체 자원의 사용률을 높이는 방법이다.

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: resource-limit-with-request-pod
  labels:
    name: resource-limit-with-request-pod
spec:
  containers:
  - name: nginx
    image: nginx:latest
    resources:
      limits:
        memory: "256Mi"
        cpu: "1000m"
      requests:
        memory: "128Mi"
        cpu: "500m"
```

- 위에 있는 yaml 설명
  - requests 에서 128Mi 를, limits 에서 256Mi 를 설정했기 때문에 ‘최소한 128Mi 의 메모리 사용은 보장되지만, 유휴 메모리 자원이 있다면 최대 256Mi까지 사용할 수 있다.’

## 11.1.3 CPU 자원 사용량의 제한 원리

- 쿠버네티스에서는 CPU 를 m(밀리코어) 단위로 제한하며, 1개의 CPU 는 1000m 에 해당한다.
  - 따라서 서버에 2개의 CPU 가 존재한다면 최대 2000m 만큼의 CPU Requests 를 포드의 컨테이너에 할당할 수 있다.
- CPU 의 Requests 는 docker run 의 —cpu-shares 옵션과 같다.

## 11.1.4 QoS 클래스와 메모리 자원 사용량 제한 원리

- 프로세스의 메모리는 이미 데이터가 메모리에 적재돼 있기 때문에 CPU 와 달리 메모리는 압축 불가능한 자원으로 취급된다.
- 쿠버네티스는 가용 메모리를 확보하기 위해 **우선순위가 낮은 포드 프로세스를 강제로 종료하도록 설계돼 있다.**
  - 강제로 종료된 포드는 다른 노드로 옮겨가게 되는데, 쿠버네티스에서는 이를 퇴거(Eviction)라고 표편한다.

# 11.2 쿠버네티스 스케줄링

- 쿠버네티스에서 말하는 스케줄링이란 컨테이너나 가상 머신과 같은 인스턴스를 새롭게 생성할 때, 그 인스턴스를 어느 서버에 생성할 것일지 결정하는 일을 뜻한다.

## 11.2.1 포드가 실제로 노드에 생성되기까지의 과정

1. ServiceAccount, RoleBinding 등의 기능을 이용해 포드 생성을 요청한 사용자의 인증 및 인가 작업을 수행
2. ResourceQuota, LimitRange 와 같은 어드미션 컨트롤러가 해당 포드 요청을 적절히 변형하거나 검증
3. 어드미션 컨트롤러의 검증을 통과해 최종적으로 포드 생성이 승인됐다면 쿠버네티스는 해당 포드를 워커 노드 중 한 곳에 생성한다.
- 스케줄링에 관여하는 컴포넌트는 `kube-scheduler` 와 `etcd` 이다.
  - kube-scheduler 는 쿠버네티스 스케줄러에 해당
  - etcd 는 쿠버네티스 클러스터의 전반적인 상태 데이터를 저장하는 일종의 데이터베이스 역할을 담당

## 11.2.3. NodeSelector 와 Node Affinity, Pod Affinity

- Node Affinity 는 nodeSelector 에서 좀 더 확장된 라벨 선택 기능을 제공하며, 반드시 충족해야 하는 조건(Hard)과 선호하는 조건(Soft) 을 별도로 정의할  수도 있다.
- Node Affinity 의 2가지 종류 옵션
  - **required**DuringSchedulingIgnoredDuringExecution
    - 반드시 만족해야 하는 제약 조건을 정의할때 쓰인다.
  - **preferred**DuringSchedulingIgnoredDuringExecution
    - 여기서 정의한 라벨의 키-값 조건은 반드시 만족해야 할 필요는 없으며, 만약 해당 조건을 만족하는 노드가 있다면 그 노드를 좀 더 선호하겠다는 뜻이다.
- Pod Affinity 를 이용한 스케줄링 방법
  - Node Affinity 가 특정 조건을 만족하는 노드를 선택하는 방법이라면, Pod Affinity 는 특정 조건을 만족하는 포드와 함께 실행되도록 스케줄링한다.
- Pod Anti-affinity 를 이용한 스케줄링 방법
  - Pod anti-affinity 는 Pod Affinity 와 반대로 동작한다. Pod Affinity 가 특정 포드와 동일한 토폴로지에 존재하는 노드를 선택한다면, Pod Anti-affinity 는 특정 포드와 같은 토폴로지의 노드를 선택하지 않는 방법이다.

# 11.3 쿠버네티스 애플리케이션 상태와 배포

## 11.3.1 디플로이먼트를 통해 롤링 업데이트

- 디플로이먼트를 이용한 레플리카셋의 버전 관리
  - 테스트 또는 개발 환경을 제외하면 대부분은 디플로이먼트를 생성하고, 디플로이먼트에 속하는 레플리카셋이 포드를 생성하는 것이 일반적이다.
- 디플로이먼트를 통한 롤링 업데이트 설정
  - 롤링 업데이트의 세부 옵션에는 maxSurge, maxUnavailable 두 가지가 있다.
  - maxUnavailable: 롤링 업데이트 도중 사용 불가능한 상태가 되는 포드의 최대 개수를 설정
  - maxSurge: 롤링 업데이트 도중 전체 포드의 개수가 디플로이먼트의 replicas 값보다 얼마나 더 많이 존재할 수 있는지 설정

    ```yaml
    ...
    spec:
      replicas: 3
      strategy:
        type: RollingUpdate
        rollingUpdate:
          maxSurge: 2
          maxUnavailable: 2
    ...
    ```


## 11.3.2 포드의 생애 주기

### 11.3.2.1 포드의 상태와 생애 주기

- 포드의 상태
  - `Pending`: 포드를 생성하는 요청이 API 서버에 의해 승인됐지만, 어떠한 이유로 인해 아직 실제로 생성되지 않은 상태
  - `Running`: 포드에 포함된 컨테이너들이 모두 생성돼 포드가 정상적으로 실행된 상태
  - `Completed`: 포드가 정상적으로 실행돼 종료됐음을 의미
  - `Error`: 포드가 정상적으로 실행되지 않은 상태로 종료됐음을 의미
  - `Terminating` : 포드가 삭제 또는 퇴거(Eviction)되기 위해 삭제 상태에 머물러 있는 경우에 해당