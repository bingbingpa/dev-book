# 3장 카프카 기본 개념과 구조

### **3.1 카프카 기초 다지기**

- 카프카를 구성하는 주요 요소
    - 주키퍼(zooKeeper): 아파치 프로젝트 애플리케이션 이름. 카프카의 메타데이터 관리 및 브로커의 정상상태 점검을 담당
    - 카프카(kafka) 또는 카프카 클러스터: 아파치 프로젝트 애플리케이션 이름. 여러 대의 브로커를 구성한 클러스터를 의미한다.
    - 브로커(broker): 카프카 애플리케이션이 설치된 서버 또는 노드
    - 프로듀서(produce): 카프카로 메시지를 보내는 역할을 하는 클라이언트를 총칭
    - 컨슈머(consumer): 카프카에서 메시지를 꺼내가는 역할을 하는 클라이언트를 총칭
    - 토픽(topic): 카프카는 메시지 피드들을 토픽으로 구분하고, 각 토픽의 이름은 카프카 내에서 고유하다.
    - 파티션(partition): 병렬 처리 및 고성능을 얻기 위해 하나의 토픽을 여러 개로 나눈 것을 말한다.
    - 세그먼트(segment): 프로듀서가 전송한 실제 메시지가 브로커의 로컬 디스크에 저장되는 파일을 말한다.
    - 메시지 또는 레코드: 프로듀서가 브로커로 전송하거나 컨슈머가 읽어가는 데이터 조각
- 리플리케이션
    - 각 메시지들을 여러 개로 복제해서 카프카 클러스터내 브로커들에 분산시키는 동작
    - `replication-factor`: 카프카 내 몇 개의 리플리케이션을 유지할지 설정하는 옵션
    - 리플리케이션 팩터 수가 커지면 안정성은 높아지지만 그만큼 브로커 리소스를 많이 사용하게 된다.
    - 리플리케이션 팩터 수 설정 기준
        - 테스트나 개발 환경: 1
        - 운영 환경(로그성 메시지로서 약간의 유실 허용): 2
        - 운영 환경(유실 허용하지 않음): 3
- 파티션
    - 하나의 토픽이 한 번에 처리할 수 있는 한계를 높이기 위해 토픽 하나를 여러 개로 나눠 병렬 처리가 가능하게 만든 것
    - 파티션 수도 토픽을 생성할 때 옵션으로 설정
        - **파티션 수는 초기 생성 후 언제든지 늘릴 수 있지만, 반대로 한번 늘린 파티션 수는 절대로 줄일수 없다.**
        - 초기에는 토픽을 생성할 때 파티션 수를 작게 2 또는 4 정도로 생성한 후, 메시지 처리량이나 컨슈머의 LAG 등을 모니터링하면서 조금씩 늘려가는 방법이 가장 좋다.
            - LAG: 프로듀서가 보낸 메시지 수(카프카에 남아 있는 메시지 수) - 컨슈머가 가져간 메시지 수
            - LAG 이라는 지표를 통해 컨슈머에 지연이 없는지 확인 할 수 있다.(모니터링 방법은 7장에서...)
        - 적절한 파티션 수를 계산해주는 컨플루언트 사이트([https://eventsizer.io](https://eventsizer.io/)). 참고용으로만 사용
- 세그먼트
    - 프로듀서에 의해 브로커로 전송된 메시지는 토픽의 파티션에 저장되며, 각 메시지들은 세그먼트라는 로그 파일의 형태로 브로커의 로컬 디스크에 저장된다.
    - 각 파티션마다 N 개의 세그먼트 로그 파일들이 존재한다.
    - 로그 디렉토리는 토픽의 파티션별로 생성된다.
    - 디렉토리에서 xxx.log 파일을 hexdump 를 보여주는 `xxd` 명령어를 이용해 확인 할 수 있다.
    - 브로커의 세그먼트 로그 파일에 저장된 메시지는 컨슈머가 읽어갈 수 있다.
        - 컨슈머는 토픽을 컨슘해서 해당 토픽 내 파티션의 세그먼트 로그 파일에서 메시지를 가져온다.

### **3.2 카프카의 핵심 개념**

- 분산 시스템
    - 네트워크상에서 연결된 컴퓨터들의 그룹
    - 카프카도 분산 시스템이므로 최초 구성한 클러스터의 리소스가 한계치에 도달해 더욱 높은 메시지 처리량이 필요한 경우, 브로커를 추가하는 방식으로 확장이 가능하다.
    - 카프카에서 브로커는 온라인 상태에서 매우 간단하게 추가할 수 있어서 확장이 용이하다.
- 페이지 캐시
    - OS 의 페이지 캐시를 활용하는 방식으로 설계되어 있다.
        - 페이지 캐시는 직접 디스크에 읽고 쓰는 대신 물리 메모리 중 애플리케이션이 사용하지 않는 일부 잔여 메모리를 활용한다.
        - 페이지 캐시를 이용하면 디스크 I/O 에 대한 접근이 줄어들므로 성능을 높일 수 있다.
- 배치 전송 처리
    - 수많은 통신을 묶어서 처리할 수 있으며, 카프카에서 권장하는 전송 방식이다.
- 압축 전송
    - 카프카는 메시지 전송 시 좀 더 성능이 높은 압축 전송 사용을 권장한다.
    - 지원하는 압축 타입: gzip, snappy, lz4, zstd 등
    - 배치 전송과 결합해 사용한다면 더욱 높은 효과를 얻게 된다.
    - **일반적으로 높은 압축률이 필요한 경우라면 gzip 이나 zstd 를 권장하고, 빠른 응답 속도가 필요하다면 lz4 나 snappy 를 권장한다.**
        - 메시지의 형식이나 크기에 따라 또 다른 결과를 나타낼 수 있으니 실제로 메시지를 전송해보면서 압축 타입별로 직접 테스트 해보는게 좋다.
- 토픽, 파티션, 오프셋
    - 카프카는 `토픽`이라는 곳에 데이터를 저장하는데, 이는 메일 전송 시스템에서 이메일 주소 정도의 개념으로 이해하면 쉽다.
    - 토픽은 병렬 처리를 위해 여러 개의 `파티션`이라는 단위로 다시 나뉜다.
        - 카프카에서는 이와 같은 파티셔닝을 통해 단 하나의 토픽이라도 높은 처리량을 수행할 수 있다.
    - 파티션의 메시지가 저장되는 위치를 `오프셋`이라고 부르며, 오프셋은 순차적으로 증가하는 숫자(64비트 정수) 형태로 되어 있다.
    - 각 파티션에서의 오프셋은 고유한 숫자로, 카프카에서는 오프셋을 통해 메시지의 순서를 보장하고 컨슈머에서는 마지막까지 읽은 위치를 알 수도 있다.
- 고가용성 보장
    - 분산 시스템이기 때문에 하나의 서버나 노드가 다운되어도 다른 서버 또는 노드가 장애가 발생한 서버의 역할을 대신해 안정적인 서비스가 가능하다.
    - 고가용성을 보장하기 위해 카프카에서는 `리플리케이션` 기능을 제공한다.
        - 토픽 자체를 복제하는 것이 아니라 토픽의 파티션을 복제하는 것이다.
        - 토픽을 생성할 때 옵션으로 리플리케이션 팩터 수를 지정할 수 있으며, 이 숫자에 따라 리플리케이션들이 존재하게 된다.
    - 원본과 리플리케이션을 구분하기 위해 리더와 팔로워라는 용어를 사용한다.
    - 리플리케이션 팩터 수에 따른 리터와 팔로워 수
      ![](https://opensesame.notion.site/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fb9d2ea75-1b44-44d1-a596-974947bfd272%2FUntitled.png?table=block&id=807e75e8-c010-437d-98fe-8b4cff389fb9&spaceId=f4775408-d01f-42fb-8eae-1614cb98b0ef&width=2000&userId=&cache=v2)

        - 리더의 숫자는 1 을 유지한 채 리플리케이션 팩터 수에 따라 팔로워 수만 증가하게 된다.
        - 팔로워의 수만큰 결구 브로커의 디스크 공간도 소비되므로, 팔로워의 수가 많다고 딱히 좋은건 아니다.
        - 일반적으로 카프카에서는 리플리케이션 팩터 수를 3으로 구성하도록 권장한다.
        - 리더는 프로듀서, 컨슈머로부터 오는 모든 읽기와 스기 요청을 처리하며, 팔로워는 오직 리더로부터 리플리케이션 하게 된다.
- 주키퍼의 의존성
    - 카프카의 중요한 메타데이터를 저장하고 각 브로커를 관리하는 중요한 역할을 한다.
    - 주키퍼는 여러 대의 서버를 크러스터로 구성하고, 살아 있는 노드 수가 과반수 이상 유지된다면 지속적인 서비스가 가능한 구조이다.
        - 따라서 주키퍼는 반드시 홀수로 구성해야 한다.
    - 지노드(znode)를 이용해 카프카의 메타 정보가 주키퍼에 기록되며, 주키퍼는 이러한 지노드를 이용해 브로커의 노드 관리, 토픽 관리, 컨트롤러 관리 등 매우 중요한 역할을 하고 있다.
    - 최근 들어 주키퍼 성능의 한계가 드러나기 시작했고, 주키퍼에 대한 의존성을 제거하려는 움직임이 진행중이다.(이미 제거된 버전이 릴리즈 되었다.)

### **3.3 프로듀서의 기본 동작과 예제 맛보기**

- 프로듀서는 카프카의 토픽으로 메시지를 전송하는 역할을 담당한다.
- 프로듀서 디자인
![](https://opensesame.notion.site/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F5bd2349a-eceb-43be-9319-b79ba9f19e5d%2FUntitled.png?table=block&id=014e29c2-462f-4ecf-8651-a0c5085dd52d&spaceId=f4775408-d01f-42fb-8eae-1614cb98b0ef&width=2000&userId=&cache=v2)

    - ProducerRecord: 카프카로 전송하기 위한 실제 데이터
    - 레코드는 토픽, 파티션, 키, 밸류로 구성
        - 토픽과 밸류(메시지 내용)는 필숫값
        - 특정 파티션을 지정하기 위한 레코드의 파티션과 특정 파티션에 레코드들을 정렬하기 위한 레코드의 키는 옵션이다.
    - 파티셔너
        - 파티션을 지정하면 파티셔너는 아무 동작도 하지 않고 지정된 파티션으로 레코드를 전달한다.
        - 파티션을 지정하지 않은 경우에는 키를 가지고 파티션을 선택해 레코드로 전달. 기본적으로는 라운드 로빈 방식으로 동작
    - 파티션별로 잠시 모았다가 배치 전송
        - 전송이 실패하면 재시도 동작이 이뤄지고, 지정된 횟수만큼의 재시도가 실패하면 최종 실패를 전달하며, 전송이 성공하면 메타데이터를 리턴
- 프로듀서의 주요 옵션
    - bootstrap.servers
        - 클라이언트가 카프카 클러스터에 처음 연결하기 위한 호스트와 포트 정보
    - client.dns.lookup
        - 하나의 호스트에 여러 IP 를 매핑해 사용하는 일부 환경에서 클라이언트가 하나의 IP 와 연결하지 못할 경우에 다른 IP 로 시도하는 설정
        - use_all_dns_ips(기본값): DNS 에 할당된 호스트의 모든 IP 를 쿼리하고 저장. 첫 번째 IP 로 접근이 실패하면, 종료하지 않고 다음 IP 로 접근 시도
        - resolve_canonical_bootstrap_server_only
            - 커버로스(kerberos)환경에서 FQDN(Fully Qualified Domain Name) 을 얻기 위한 용도로 사용
                - 커버로스는 티켓(ticket) 기반의 컴퓨터 네트워크 인증 프로토콜이다.
                - 보안이 보장되지 않은 네트워크 환경에서 요청을 보내는 유저와 요청을 받는 서버가 서로의 신뢰성을 확보하기 위해 사용된다.
    - acks
        - 프로듀서가 카프카 토픽의 리더 측에 메시지를 전송한 후 요청을 완료하기를 결정하는 옵션
        - 0: 빠른 전송을 의미하지만, 일부 메시지 손실 가능
        - 1: 리더가 메시지를 받았는지 확인하지만, 모든 팔로워를 전부 확인하지는 않는다. **대부분 기본값으로 1을 사용한다.**
        - all(또는 -1): 팔로워가 메시지를 받았는지 여부를 확인, 다소 느릴 수는 있지만, 하나의 팔로워가 있는 한 메시지는 손실되지 않는다.
    - buffer.memory
        - 프로듀서가 카프카 서버로 데이터를 보내기 위해 잠시 대기(배치 전송이나 딜레이 등) 할 수 있는 전체 메모리 바이트
    - compression.type
        - 프로듀서가 메시지 전송 시 선택할 수 있는 압축 타입
        - none, gzip, snappy, lz4, zstd 중 원하는 타입을 선택
    - enable.idempotence
        - 설정을 true 로 하는 경우 중복 없는 전송 가능
        - 이와 동시에 max.in.flight.requests.per.connection 은 5 이하, retries 는 0 이상, acks 는 all 로 설정해야 한다.
    - max.in.flight.requests.per.connection
        - 하나의 커넥션에서 프로듀서가 최대한 ACK 없이 전송할 수 있는 요청 수
        - 메시지의 순서가 중요하다면 1로 설정할 것을 권장하지만, 성능은 다소 떨어진다.
    - retries
        - 일시적인 오류로 인해 전송에 실패한 데이터를 다시 보내는 횟수
    - batch.size
    - linger.ms
        - 배치 형태의 메시지를 보내기 전에 추가적인 메시지를 위해 기다리는 시간
        - 배치 크기에 도달하지 못한 상황에서 linger.ms 제한 시간에 도달했을 때 메시지를 전송한다.
    - transactional.id
        - `정확히 한 번 전송`을 위해 사용하는 옵션
        - 동일한 TransactionalId 에 한해 정확히 한 번을 보장
        - 옵션을 사용하기 전 `enable.idempotence 를 true 로 설정`해야 한다.

### **3.4 컨슈머의 기본 동작과 예제 맛보기**

- 컨슈머의 기본 동작
    - 프로듀서가 카프카의 토픽으로 메시지를 전송하면 해당 메시지들은 브로커들의 로컬 디스크에 저장된다.
    - 그리고 컨슈머를 이용해 토픽에 저장된 메시지를 가져올 수 있다.
    - 컨슈머 그룹은 하나 이상의 컨슈머들이 모여 있는 그룹을 의미하고, 컨슈머는 반드시 컨슈머 그룹에 속하게 된다.
    - 컨슈머 그룹은 각 파티션의 리더에게 카프카 토픽에 저장된 메시지를 가져오기 위한 요청을 보낸다.
        - **이 때 파티션 수와 컨슈머 수(하나의 컨슈머 그룹 안에 있는 컨슈머 수)는 일대일로 매핑되는 것이 이상적이다.**
        - 컨슈머 수가 파티션 수보다 더 많다고 해도 그냥 대기 상태로만 존재한다.
        - 굳이 장애 대비를 위한 추가 컨슈머 리소스를 할당하지 않아도 된다.
- 컨슈머 주요 옵션
    - bootstrap.servers
        - 프로듀서와 동일하게 브로커의 정보를 입력
    - fetch.min.bytes
        - 한 번에 가져올 수 있는 최소 데이터 크기
        - 만약 지정한 크기보다 작은 경우, 요청에 응답하지 않고 데이터가 누적될 때까지 기다린다.
    - group.id
        - 컨슈머가 속한 컨슈머 그룹을 식별하는 식별자
        - 동일한 그룹내의 컨슈머 정보는 모두 공유된다.
    - heartbeat.interval.ms
        - 하트비트가 있다는 것은 컨슈머의 상태가 active 임을 의미한다.
        - session.timeout.ms 와 밀접한 관계가 있으며, session.timeout.ms 보다 낮은 값으로 설정해야 한다.
        - 일반적으로 session.timeout.ms 의 1/3 로 설정
    - max.partition.fetch.bytes
        - 파티션당 가져올 수 있는 최대 크기를 의미한다.
    - session.timeout.ms
        - 이 시간을 이용해, 컨슈머가 종료된 것인지를 판단한다.
        - 컨슈머는 주기적으로 하트비트를 보내야 하고, 만약 이 시간 전까지 하트비트를 보내지 않았다면 해당 컨슈머는 종료된 것으로 간주하고 컨슈머 그룹에서 제외하고 리밸런싱을 시작한다.
    - enable.auto.commit
        - 백그라운드로 주기적으로 오프셋을 커밋한다.
    - auto.offset.reset
        - 카프카에서 초기 오프셋이 없거나 현재 오프셋이 더 이상 존재하지 않는 경우에 다음 옵션으로 rest
            - earliest: 가장 초기의 오프셋값으로 설정
            - latest: 가장 마지막의 오프셋값으로 설정
            - none: 이전 오프셋값을 찾지 못하면 에러를 나타낸다.
    - fetch.max.bytes
        - 한 번의 가져오기 요청으로 가져올 수 있는 최대 크기
    - group.instance.id
        - 컨슈머의 고유한 식별자
        - 만약 설정한다면 static 멤버로 간주되어, 불필요한 리밸런싱을 하지 않는다.
    - isolation.level
        - 트랜잭션 컨슈머에서 사용되는 옵션으로, read_uncommitted 는 기본값으로 모든 메시지를 읽고, read_committed 는 트랜잭션이 완료된 메시지만 읽는다.
    - max.poll.records
        - 한 번의 poll() 요청으로 가져오는 최대 메시지 수
    - partition.assignment.strategy
        - 파티션 할당 전략이며, 기본값은 range
    - fetch.max.wait.ms
        - fetch.min.bytes 에 의해 설정된 데이터보다 적은 경우 요청에 대한 응답을 기다리는 최대 시간